{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Data Wrangling Demo\n",
    "\n",
    "This notebook demonstrates various pandas operations and data wrangling techniques, structured to match the LIVE DEMO sections from the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Pandas Operations and Data Structures\n",
    "\n",
    "In this section, we'll cover the fundamental pandas data structures (Series and DataFrame) and basic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([1, 3, 5, np.nan, 6, 8])\n",
    "print(\"Series:\")\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pandas Series is a one-dimensional labeled array that can hold data of any type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': ['p', 'q', 'r']\n",
    "})\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a 2-dimensional labeled data structure with columns of potentially different types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic operations\n",
    "print(\"\\nSelect column 'A':\")\n",
    "print(df['A'])\n",
    "\n",
    "print(\"\\nFilter rows where A > 1:\")\n",
    "print(df[df['A'] > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select specific columns and filter rows based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column\n",
    "df['D'] = df['A'] * 2\n",
    "print(\"\\nDataFrame with new column 'D':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New columns can be added to a DataFrame by assigning values to a new column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data\n",
    "df.loc[1, 'B'] = np.nan\n",
    "print(\"\\nFill missing values with mean:\")\n",
    "print(df['B'].fillna(df['B'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas provides methods to handle missing data, such as `fillna()` to replace NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "df['C'] = df['C'].astype('category')\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert column data types using the `astype()` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combining and Reshaping Data\n",
    "\n",
    "This section covers techniques for combining multiple DataFrames and reshaping data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1'], 'B': ['B0', 'B1']})\n",
    "df2 = pd.DataFrame({'A': ['A2', 'A3'], 'B': ['B2', 'B3']})\n",
    "\n",
    "# Concatenate DataFrames\n",
    "result = pd.concat([df1, df2])\n",
    "print(\"Concatenated DataFrame:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.concat()` is used to concatenate DataFrames along a particular axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DataFrames\n",
    "left = pd.DataFrame({'key': ['K0', 'K1'], 'A': ['A0', 'A1']})\n",
    "right = pd.DataFrame({'key': ['K0', 'K2'], 'B': ['B0', 'B2']})\n",
    "merged = pd.merge(left, right, on='key', how='outer')\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.merge()` is used to merge DataFrames based on a common key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data: Melt\n",
    "df = pd.DataFrame({'A': ['a', 'b'], 'B': [1, 3], 'C': [2, 4]})\n",
    "melted = pd.melt(df, id_vars=['A'], value_vars=['B', 'C'])\n",
    "print(\"\\nMelted DataFrame:\")\n",
    "print(melted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd.melt()` is used to reshape data from wide to long format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data: Pivot\n",
    "pivoted = melted.pivot(index='A', columns='variable', values='value')\n",
    "print(\"\\nPivoted DataFrame:\")\n",
    "print(pivoted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pivot()` is used to reshape data from long to wide format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning Techniques\n",
    "\n",
    "This section demonstrates various techniques for cleaning and preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with issues\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4, 5],\n",
    "    'B': [5, 6, 7, np.nan, 9],\n",
    "    'C': ['a', 'b', 'a', 'c', 'b'],\n",
    "    'D': pd.date_range(start='2023-01-01', periods=5)\n",
    "})\n",
    "\n",
    "# Handle missing data\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDropping rows with missing values:\")\n",
    "print(df.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dropna()` is used to remove rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df = df.append(df.iloc[0])  # Add a duplicate row\n",
    "print(\"\\nRemoving duplicates:\")\n",
    "print(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`drop_duplicates()` is used to remove duplicate rows from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String operations\n",
    "df['C'] = df['C'].str.upper()\n",
    "print(\"\\nAfter string operation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String methods can be applied to string columns using the `str` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date operations\n",
    "df['Year'] = df['D'].dt.year\n",
    "print(\"\\nAfter extracting year:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date and time operations can be performed using the `dt` accessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data\n",
    "df['C'] = df['C'].astype('category')\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting appropriate columns to categorical type can improve memory usage and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Data Wrangling Techniques\n",
    "\n",
    "This section covers more advanced data manipulation techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom function application\n",
    "def celsius_to_fahrenheit(celsius):\n",
    "    return (celsius * 9/5) + 32\n",
    "\n",
    "df = pd.DataFrame({'Celsius': [0, 10, 20, 30]})\n",
    "df['Fahrenheit'] = df['Celsius'].apply(celsius_to_fahrenheit)\n",
    "print(\"After applying custom function:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `apply()` method allows us to apply custom functions to DataFrame columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table\n",
    "df = pd.DataFrame({\n",
    "    'A': ['foo', 'foo', 'bar', 'bar'],\n",
    "    'B': ['one', 'two', 'one', 'two'],\n",
    "    'C': [1, 2, 3, 4]\n",
    "})\n",
    "pivot = df.pivot_table(values='C', index='A', columns='B', aggfunc='sum')\n",
    "print(\"\\nPivot table:\")\n",
    "print(pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot tables are used to create spreadsheet-style pivot tables as a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data validation\n",
    "valid_categories = ['foo', 'bar']\n",
    "df['is_valid'] = df['A'].isin(valid_categories)\n",
    "print(\"\\nAfter data validation:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `isin()` method is useful for checking if each element in a Series is contained in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning data\n",
    "df = pd.DataFrame({'value': [1, 5, 10, 15, 20]})\n",
    "df['bin'] = pd.cut(df['value'], bins=[0, 5, 15, 20], labels=['low', 'medium', 'high'])\n",
    "print(\"\\nAfter binning:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cut()` function is used to bin values into discrete intervals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
